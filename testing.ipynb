{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = datasets.load_digits()\n",
    "\n",
    "# Make array representation of labels\n",
    "y = []\n",
    "for x in data.target:\n",
    "    r = [0,0,0,0,0,0,0,0,0,0]\n",
    "    r[x] = 1\n",
    "    y.append(r)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.data, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with data\n",
    "\n",
    "print(data.target)\n",
    "print(len(data.target))\n",
    "print(len(y))\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test if import works correctly\n",
    "import numpy as np\n",
    "\n",
    "i = 7\n",
    "print(y_train[i])\n",
    "img = np.reshape(x_train[i], (-1, 8))\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(img, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "layer_sizes = [64,64,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Activation function, should be the logistic function\n",
    "def afunc(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "# Derivative of the activation function\n",
    "def afuncDerivative(x):\n",
    "    return x*(1-x)\n",
    "    \n",
    "\n",
    "# Initialization of layers\n",
    "layers = []\n",
    "for i in range(len(layer_sizes)):\n",
    "    layers.append(2*np.random.random((layer_sizes[i],1)) - 1)\n",
    "    \n",
    "# Initialization of weights\n",
    "weights = []\n",
    "for i in range(1,len(layer_sizes)):\n",
    "    weights.append(2*np.random.random((layer_sizes[i-1],layer_sizes[i])) - 1)\n",
    "    \n",
    "# Training function\n",
    "def train(training_set):\n",
    "    for x in range(len(x_train)):\n",
    "        output = None\n",
    "        \n",
    "        # Calculates the values of each neuron in each layer\n",
    "        layer_output = []\n",
    "        layer_output.append(x_train[x])\n",
    "        for i in range(len(weights)):\n",
    "            layer_output.append(layer_output[-1]*weights[i])\n",
    "        output = layer_output[-1]\n",
    "        \n",
    "        # Calculates the gradien for each weight\n",
    "        gradients = []\n",
    "        for x in range(len(weights)):\n",
    "            break\n",
    "    \n",
    "    return None\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check weight initialization\n",
    "for x in weights:\n",
    "    print(len(x))\n",
    "    print(len(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer x:  (1203, 64)\n",
      "layer x+1:  (1203, 64)\n",
      "weights x:  64\n",
      "weights x[x]:  64\n",
      "dotproduct:  (64, 64)\n",
      "layer x:  (1203, 64)\n",
      "layer x+1:  (1203, 10)\n",
      "weights x:  64\n",
      "weights x[x]:  10\n",
      "dotproduct:  (64, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculates the values of each neuron in each layer\n",
    "layer_output = []\n",
    "layer_output.append(x_train)\n",
    "for i in range(len(weights)):\n",
    "    layer_output.append(afunc(layer_output[-1].dot(weights[i])))\n",
    "\n",
    "# Testing lines to be deleted    \n",
    "#print((str(len(layer_output))+\" \"+str(len(layer_output[0]))+\" \"+str(len(layer_output[0][0]))))\n",
    "#print(str(len(weights))+\" \"+str(len(weights[1]))+\" \"+str(len(weights[1][0])))\n",
    "#for x in range(len(weights)-1,-1,-1):\n",
    "#    print(x)\n",
    "    \n",
    "# Error function to be deleted\n",
    "error = 1/2*(layer_output[-1]-y_train)**2\n",
    "sum_error = np.sum(error)\n",
    "\n",
    "# Gradient calculation\n",
    "gradients = []\n",
    "s1 = (y_train-layer_output[-1])\n",
    "for x in range(len(weights)-1,-1,-1):\n",
    "    grad =s1*afuncDerivative(layer_output[x+1])\n",
    "    gradients.insert(0,grad)\n",
    "    if x!=0: s1 = gradients[0].dot(weights[x].T)\n",
    "\n",
    "\n",
    "    \n",
    "# Update weights\n",
    "for x in range(len(weights)):\n",
    "    print(\"layer x: \", layer_output[x].shape)\n",
    "    print(\"layer x+1: \", layer_output[x+1].shape)\n",
    "    print(\"weights x: \",len(weights[x]))\n",
    "    print(\"weights x[x]: \",len(weights[x][x]))\n",
    "\n",
    "    print(\"dotproduct: \",layer_output[x].T.dot(layer_output[x+1]).shape)\n",
    "    weights[x] += layer_output[x].T.dot(layer_output[x+1])\n",
    "    \n",
    "# Print layers\n",
    "for x in layer_output:\n",
    "    #print(x)\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
